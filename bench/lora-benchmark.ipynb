{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e69b7-a34d-43fc-ad41-5bb65752e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import punica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0b009-5df4-419a-9314-b33fb7ee2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be996816-be42-4cc2-a906-d8d38c2687b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench(f, *, device=\"cuda:0\", min_repeat: int, min_secs: float) -> np.ndarray:\n",
    "    cache = torch.empty(int(256e6 // 4), dtype=torch.int, device=device)\n",
    "    latency = []\n",
    "    \n",
    "    # First run\n",
    "    torch.cuda.synchronize()\n",
    "    st = time.perf_counter_ns()\n",
    "    f()\n",
    "    torch.cuda.synchronize()\n",
    "    ed = time.perf_counter_ns()\n",
    "    latency.append((ed-st)/1e9)\n",
    "    \n",
    "    # Subsequent runs, until reaching both min_repeat and min_secs\n",
    "    min_nanos = int(min_secs * 1e9)\n",
    "    start_nanos = time.perf_counter_ns()\n",
    "    while True:\n",
    "        now_nanos = time.perf_counter_ns()\n",
    "        if len(latency) > min_repeat and now_nanos - start_nanos > min_nanos:\n",
    "            break\n",
    "        cache.zero_()\n",
    "        torch.cuda.synchronize()\n",
    "        st = time.perf_counter_ns()\n",
    "        f()\n",
    "        torch.cuda.synchronize()\n",
    "        ed = time.perf_counter_ns()\n",
    "        latency.append((ed-st)/1e9)\n",
    "    return np.array(latency)\n",
    "\n",
    "def tail_mean_std(xs, skip=0.2):\n",
    "    a = xs[int(len(xs) * skip):]\n",
    "    return a.mean(), a.std()\n",
    "\n",
    "def fmt_avg_std(xs, skip=0.2):\n",
    "  a = xs[int(len(xs) * skip):] * 1e6\n",
    "  return f\"{a.mean():.3f} us +/- {a.std():.3f} us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82cf4d-d414-4f96-8c5e-c8908f539f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lora_bmm(\n",
    "    y: torch.Tensor,  # (batch_size, 1, out_features)\n",
    "    x: torch.Tensor,  # (batch_size, 1, in_features)\n",
    "    A: torch.Tensor,  # (batch_size, in_features, lora_rank)\n",
    "    B: torch.Tensor,  # (batch_size, lora_rank, out_features)\n",
    "):\n",
    "  y[:, :] += x @ A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedf953-4567-47d7-bd8b-d6e573f4f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lora_loop(\n",
    "    y: torch.Tensor,  # (batch_size, 1, out_features)\n",
    "    x: torch.Tensor,  # (batch_size, 1, in_features)\n",
    "    A: torch.Tensor,  # (num_loras, in_features, lora_rank)\n",
    "    B: torch.Tensor,  # (num_loras, lora_rank, out_features)\n",
    "    I: torch.LongTensor,  # (batch_size,)\n",
    "):\n",
    "  for i, idx in enumerate(I.cpu().numpy()):\n",
    "    y[i] += x[i] @ A[idx] @ B[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47698196-1c2e-4947-80c3-ec0471981d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lora_gbmm(\n",
    "    y: torch.Tensor,  # (batch_size, 1, out_features)\n",
    "    x: torch.Tensor,  # (batch_size, 1, in_features)\n",
    "    A: torch.Tensor,  # (num_loras, in_features, lora_rank)\n",
    "    B: torch.Tensor,  # (num_loras, lora_rank, out_features)\n",
    "    I: torch.LongTensor,  # (batch_size,)\n",
    "):\n",
    "  a = torch.index_select(A, 0, I) # (batch_size, in_features, lora_rank)\n",
    "  b = torch.index_select(B, 0, I) # (batch_size, lora_rank, out_features)\n",
    "  y[:, :] += x @ a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237094c-d5d3-47a8-8ec8-c0e9a500a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lora_punica(\n",
    "    y: torch.Tensor,  # (batch_size, out_features)\n",
    "    x: torch.Tensor,  # (batch_size, in_features)\n",
    "    wa_T_all: torch.Tensor,  # (num_loras, num_layers, lora_rank, in_features)\n",
    "    wb_T_all: torch.Tensor,  # (num_loras, num_layers, out_features, lora_rank)\n",
    "    lora_indices: torch.LongTensor,  # (batch_size,)\n",
    "):\n",
    "  punica.ops.add_lora(y, x, wa_T_all, wb_T_all, lora_indices, layer_idx=0, scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417e1ca-17eb-4c22-a428-6c798e3eae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_lora_bs():\n",
    "  torch.manual_seed(0xabcdabcd987)\n",
    "  dtype = torch.float16\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  \n",
    "  num_loras = 50\n",
    "  h1 = 4096\n",
    "  h2 = 11008\n",
    "  r = 16\n",
    "  \n",
    "  wa_all = torch.randn(num_loras, h1, r, dtype=dtype, device=device)\n",
    "  wb_all = torch.randn(num_loras, r, h2, dtype=dtype, device=device)\n",
    "  wa_T_all = wa_all.unsqueeze(1).transpose(-1, -2).contiguous()\n",
    "  wb_T_all = wb_all.unsqueeze(1).transpose(-1, -2).contiguous()\n",
    "\n",
    "  bs_list = np.arange(1, 33)\n",
    "  res = dict(bmm=[], loop=[], gbmm=[], punica=[])\n",
    "  for bs in tqdm(bs_list):\n",
    "    x = torch.randn(bs, 1, h1, dtype=dtype, device=device)\n",
    "    y = torch.randn(bs, 1, h2, dtype=dtype, device=device)\n",
    "    indices = torch.randint(num_loras, (bs,), dtype=torch.long, device=device)\n",
    "    a = torch.index_select(wa_all, 0, indices)\n",
    "    b = torch.index_select(wb_all, 0, indices)\n",
    "\n",
    "    y_bmm = y.clone()\n",
    "    lora_bmm(y_bmm, x, a, b)\n",
    "    \n",
    "    y_loop = y.clone()\n",
    "    lora_loop(y_loop, x, wa_all, wb_all, indices)\n",
    "    \n",
    "    y_gbmm = y.clone()\n",
    "    lora_gbmm(y_gbmm, x, wa_all, wb_all, indices)\n",
    "    # torch.testing.assert_close(y_loop, y_gbmm, rtol=1e-2, atol=1e-2)\n",
    "\n",
    "    x_punica = x.squeeze(1).clone()\n",
    "    y_punica = y.squeeze(1).clone()\n",
    "    lora_punica(y_punica, x_punica, wa_T_all, wb_T_all, indices)\n",
    "    # torch.testing.assert_close(y_loop, y_punica, rtol=1e-2, atol=1e-2)\n",
    "\n",
    "    res[\"bmm\"].append(tail_mean_std(bench(lambda: lora_bmm(y, x, a, b), min_repeat=20, min_secs=2)))\n",
    "    res[\"loop\"].append(tail_mean_std(bench(lambda: lora_loop(y, x, wa_all, wb_all, indices), min_repeat=20, min_secs=2)))\n",
    "    res[\"gbmm\"].append(tail_mean_std(bench(lambda: lora_gbmm(y, x, wa_all, wb_all, indices), min_repeat=20, min_secs=2)))\n",
    "    res[\"punica\"].append(tail_mean_std(bench(lambda: lora_punica(y_punica, x_punica, wa_T_all, wb_T_all, indices), min_repeat=20, min_secs=2)))\n",
    "  ret = {\n",
    "    k: dict(avg=np.array([avg for avg, std in v]),\n",
    "            std=np.array([std for avg, std in v]))\n",
    "    for k, v in res.items()\n",
    "  }\n",
    "  return bs_list, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f8a93-6cbe-4fce-bff3-9973b323aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, res = bench_lora_bs()\n",
    "with gzip.open(\"data/20230911-lora-ops.pkl.gz\", \"wb\") as f:\n",
    "  pickle.dump((bs, res), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6368b2-a910-4681-bfd5-b97b9e1a95f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0b512-b8ff-4ab6-9bde-e77755a6a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_backbone_vs_lora():\n",
    "  torch.manual_seed(0xabcdabcd987)\n",
    "  dtype = torch.float16\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  \n",
    "  h1 = 4096\n",
    "  h2 = 11008\n",
    "  r = 16\n",
    "  \n",
    "  bs_list = np.arange(1, 33)\n",
    "  res = dict(backbone=[], lora=[])\n",
    "  for bs in tqdm(bs_list):\n",
    "    w = torch.randn(h1, h2, dtype=dtype, device=device)\n",
    "    wa = torch.randn(bs, h1, r, dtype=dtype, device=device)\n",
    "    wb = torch.randn(bs, r, h2, dtype=dtype, device=device)\n",
    "    x = torch.randn(bs, 1, h1, dtype=dtype, device=device)\n",
    "    \n",
    "    res[\"backbone\"].append(tail_mean_std(bench(lambda: x @ w, min_repeat=20, min_secs=2)))\n",
    "    res[\"lora\"].append(tail_mean_std(bench(lambda: x @ wa @ wb, min_repeat=20, min_secs=2)))\n",
    "  ret = {\n",
    "    k: dict(avg=np.array([avg for avg, std in v]),\n",
    "            std=np.array([std for avg, std in v]))\n",
    "    for k, v in res.items()\n",
    "  }\n",
    "  return bs_list, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff5d8f-9242-483f-81d2-da0abc5092c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, res = bench_backbone_vs_lora()\n",
    "with gzip.open(\"data/20230911-backbone-vs-lora.pkl.gz\", \"wb\") as f:\n",
    "  pickle.dump((bs, res), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e0686-cfa6-4393-a9fd-327d4cb32939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
